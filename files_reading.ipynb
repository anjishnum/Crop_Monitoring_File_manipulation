{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOqbdU8qfeErd+aBm6jigI7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjishnum/Crop_Monitoring_File_manipulation/blob/main/files_reading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwZPZm0g3GLE",
        "outputId": "2ec75a12-ef52-41e2-a682-44bf8728d2da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "import re\n",
        "from natsort import natsorted"
      ],
      "metadata": {
        "id": "n_A-CeXT3Jtn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to replace specific lines in a file given the line number\n",
        "def replace_line(file_name, line_num, text):\n",
        "  lines = open(file_name, 'r').readlines()\n",
        "  lines[line_num] = text\n",
        "  out = open(file_name, 'w')\n",
        "  out.writelines(lines)\n",
        "  out.close()"
      ],
      "metadata": {
        "id": "sAUYU8oqF1LJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to copy all files from the current directory to the 'newfiles' subdirectory\n",
        "def copy_files(filelist):\n",
        "  src = os.getcwd()+'/'\n",
        "  trg = os.getcwd()+'/newfiles/'\n",
        " \n",
        "  for filename in filelist:\n",
        "      \n",
        "    shutil.copy2(os.path.join(src,filename), trg)"
      ],
      "metadata": {
        "id": "Wq3-wUc8KWLa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 60%"
      ],
      "metadata": {
        "id": "qUgurzhQdOQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nitrate"
      ],
      "metadata": {
        "id": "tKDy1EHWebXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change directory\n",
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_60%/Nitrate')\n",
        "\n",
        "# make a new folder named 'newfiles' within current directory if it doesn't already exist\n",
        "try:\n",
        "  os.mkdir('newfiles')\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "# list the contents of the current directory and sort them in ascending order of their names \n",
        "filelist = sorted(os.listdir())"
      ],
      "metadata": {
        "id": "kbPN-5d3alU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copies files from current directory to 'newfiles' directory. Last item is skipped as it is the 'newfiles' directory itself\n",
        "copy_files(filelist[:-1:])"
      ],
      "metadata": {
        "id": "k69qwy9FMD4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change directory to 'newfiles' and then list contents of that directory in ascending order of naming\n",
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_60%/Nitrate/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "# iterate through each file in the list of files within 'newfiles' directory\n",
        "for filename in filelist:\n",
        "\n",
        "  c = 0\n",
        "\n",
        "  # loop to replace the 1st, 2nd and 4th line in the csv files with a blank ('') i.e. removing those lines. Files are then overwritten\n",
        "  for i in range(3):\n",
        "    if i<2:\n",
        "      replace_line(os.getcwd()+'/'+filename, c, '')\n",
        "    else:\n",
        "      replace_line(os.getcwd()+'/'+filename, c+1, '')\n",
        "\n",
        "  # df variable stores the table from one file\n",
        "  df = pd.read_csv(os.getcwd()+'/'+filename)\n",
        "\n",
        "  # delete the last column with no value from the dataframe\n",
        "  del df[df.columns[-1]]\n",
        "\n",
        "  # create a new dataframe\n",
        "  df_new = pd.DataFrame()\n",
        "\n",
        "  # loop over all the years and stacks values for different years as different columns\n",
        "  for yr in range(1980,2010):\n",
        "    df_new['N'+str(yr)] = pd.Series(list(df[df['year']==yr].iloc[:,2]))\n",
        "\n",
        "  # file overwritten with the new dataframe\n",
        "  df_new.to_csv(os.getcwd()+'/'+filename,index=False)"
      ],
      "metadata": {
        "id": "PWmi1sku4nqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yield"
      ],
      "metadata": {
        "id": "R6xEZX0XIDC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_60%/Yield')\n",
        "try:\n",
        "  os.mkdir('newfiles')\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "filelist = sorted(os.listdir())"
      ],
      "metadata": {
        "id": "A3xwYc9HORAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files(filelist[:-1:])"
      ],
      "metadata": {
        "id": "x8pQdCDjORAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_60%/Yield/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "for filename in filelist:\n",
        "\n",
        "  c = 0\n",
        "\n",
        "  for i in range(3):\n",
        "    if i<2:\n",
        "      replace_line(os.getcwd()+'/'+filename, c, '')\n",
        "    else:\n",
        "      replace_line(os.getcwd()+'/'+filename, c+1, '')\n",
        "\n",
        "  df = pd.read_csv(os.getcwd()+'/'+filename)\n",
        "  \n",
        "  # create copies of the dataframe to be named as df_wheat and df_maize\n",
        "  df_wheat = df.copy()\n",
        "  df_maize = df.copy()\n",
        "\n",
        "  # to get the columns for wheat\n",
        "  df_wheat = df_wheat.iloc[:,[0,1,3,5,6,7]]\n",
        "\n",
        "  # to get the years with wheat production\n",
        "  df_wheat = df_wheat.iloc[1::2]\n",
        "\n",
        "  # to get the columns for maize\n",
        "  df_maize = df_maize.iloc[:,[0,2,4,5,6,7]]\n",
        "\n",
        "  # to get the years with maize production\n",
        "  df_maize = df_maize.iloc[::2]\n",
        "\n",
        "  # write the dataframes into two different sheets in a new excel file within the 'newfiles' directory\n",
        "  with pd.ExcelWriter(os.getcwd()+'/'+filename[:-4:]+'.xlsx') as writer:\n",
        "    df_wheat.to_excel(writer, sheet_name='Wheat', index=False)\n",
        "    df_maize.to_excel(writer, sheet_name='Maize', index=False)\n"
      ],
      "metadata": {
        "id": "jHSDjAM0ORAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the csv files contained within the 'newfiles' directory and keep only the excel files\n",
        "for item in filelist:\n",
        "    if item.endswith(\".csv\"):\n",
        "        os.remove(os.path.join(os.getcwd(), item))"
      ],
      "metadata": {
        "id": "AB-klYCfUsGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 100%"
      ],
      "metadata": {
        "id": "d6MGKD-0dWDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nitrate"
      ],
      "metadata": {
        "id": "eh3jiteafOIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_100%/Nitrate')\n",
        "try:\n",
        "  os.mkdir('newfiles')\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "filelist = sorted(os.listdir())"
      ],
      "metadata": {
        "id": "r4vVajPNIVVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files(filelist[:-1:])"
      ],
      "metadata": {
        "id": "79je1J9TIVVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_100%/Nitrate/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "for filename in filelist:\n",
        "\n",
        "  c = 0\n",
        "\n",
        "  for i in range(3):\n",
        "    if i<2:\n",
        "      replace_line(os.getcwd()+'/'+filename, c, '')\n",
        "    else:\n",
        "      replace_line(os.getcwd()+'/'+filename, c+1, '')\n",
        "\n",
        "  df = pd.read_csv(os.getcwd()+'/'+filename)\n",
        "\n",
        "  del df[df.columns[-1]]\n",
        "\n",
        "  df_new = pd.DataFrame()\n",
        "\n",
        "  for yr in range(1980,2010):\n",
        "    df_new['N'+str(yr)] = pd.Series(list(df[df['year']==yr].iloc[:,2]))\n",
        "\n",
        "  df_new.to_csv(os.getcwd()+'/'+filename,index=False)"
      ],
      "metadata": {
        "id": "BD05cPnBIVVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yield"
      ],
      "metadata": {
        "id": "eKUlxJ4tfQbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_100%/Yield')\n",
        "try:\n",
        "  os.mkdir('newfiles')\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "filelist = sorted(os.listdir())"
      ],
      "metadata": {
        "id": "N-nQZMUEXtfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new list of files having size > 300 bytes, to then copy into the newfiles directory\n",
        "\n",
        "filelist_copy = []\n",
        "for filename in filelist[:-1:]:\n",
        "  if os.stat(filename).st_size > 300:\n",
        "    filelist_copy.append(filename)\n",
        "\n",
        "filelist = filelist_copy"
      ],
      "metadata": {
        "id": "UTDfXtQbfraD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files(filelist[::])"
      ],
      "metadata": {
        "id": "U586lqiYXtfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_100%/Yield/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "for filename in filelist:\n",
        "\n",
        "  c = 0\n",
        "\n",
        "  for i in range(3):\n",
        "    if i<2:\n",
        "      replace_line(os.getcwd()+'/'+filename, c, '')\n",
        "    else:\n",
        "      replace_line(os.getcwd()+'/'+filename, c+1, '')\n",
        "\n",
        "  df = pd.read_csv(os.getcwd()+'/'+filename)\n",
        "  \n",
        "  df_wheat = df.copy()\n",
        "  df_maize = df.copy()\n",
        "\n",
        "  # to get the columns for wheat\n",
        "  df_wheat = df_wheat.iloc[:,[0,1,3,5,6,7]]\n",
        "\n",
        "  # to get the years with wheat production\n",
        "  df_wheat = df_wheat.iloc[1::2]\n",
        "\n",
        "  # to get the columns for maize\n",
        "  df_maize = df_maize.iloc[:,[0,2,4,5,6,7]]\n",
        "\n",
        "  # to get the years with maize production\n",
        "  df_maize = df_maize.iloc[::2]\n",
        "\n",
        "  with pd.ExcelWriter(os.getcwd()+'/'+filename[:-4:]+'.xlsx') as writer:\n",
        "    df_wheat.to_excel(writer, sheet_name='Wheat', index=False)\n",
        "    df_maize.to_excel(writer, sheet_name='Maize', index=False)\n"
      ],
      "metadata": {
        "id": "lE9zbyWIXtfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in filelist:\n",
        "    if item.endswith(\".csv\"):\n",
        "        os.remove(os.path.join(os.getcwd(), item))"
      ],
      "metadata": {
        "id": "jbtuKQ7RXtfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrated"
      ],
      "metadata": {
        "id": "0xA1Knt7db4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nitrate"
      ],
      "metadata": {
        "id": "J_gi-Uolfkp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_Integrated/Nitrate')\n",
        "try:\n",
        "  os.mkdir('newfiles')\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "filelist = sorted(os.listdir())"
      ],
      "metadata": {
        "id": "bo5FMhgFJaQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files(filelist[:-1:])"
      ],
      "metadata": {
        "id": "vrxLMHdNJaQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_Integrated/Nitrate/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "for filename in filelist:\n",
        "\n",
        "  c = 0\n",
        "\n",
        "  for i in range(3):\n",
        "    if i<2:\n",
        "      replace_line(os.getcwd()+'/'+filename, c, '')\n",
        "    else:\n",
        "      replace_line(os.getcwd()+'/'+filename, c+1, '')\n",
        "\n",
        "  df = pd.read_csv(os.getcwd()+'/'+filename)\n",
        "\n",
        "  del df[df.columns[-1]]\n",
        "\n",
        "  df_new = pd.DataFrame()\n",
        "\n",
        "  for yr in range(1980,2010):\n",
        "    df_new['N'+str(yr)] = pd.Series(list(df[df['year']==yr].iloc[:,2]))\n",
        "\n",
        "  df_new.to_csv(os.getcwd()+'/'+filename,index=False)"
      ],
      "metadata": {
        "id": "IWOkoFBcJaQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yield"
      ],
      "metadata": {
        "id": "KrUI9C7bfmtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_Integrated/Yield')\n",
        "try:\n",
        "  os.mkdir('newfiles')\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "filelist = sorted(os.listdir())"
      ],
      "metadata": {
        "id": "yr5NXTeYihhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new list of files having size > 300 bytes, to then copy into the newfiles directory\n",
        "\n",
        "filelist_copy = []\n",
        "for filename in filelist[:-1:]:\n",
        "  if os.stat(filename).st_size > 300:\n",
        "    filelist_copy.append(filename)\n",
        "\n",
        "filelist = filelist_copy"
      ],
      "metadata": {
        "id": "JQCqJfrIihhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files(filelist[::])"
      ],
      "metadata": {
        "id": "K9Ffl8O1ihhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_Integrated/Yield/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "for filename in filelist:\n",
        "\n",
        "  c = 0\n",
        "\n",
        "  for i in range(3):\n",
        "    if i<2:\n",
        "      replace_line(os.getcwd()+'/'+filename, c, '')\n",
        "    else:\n",
        "      replace_line(os.getcwd()+'/'+filename, c+1, '')\n",
        "\n",
        "  df = pd.read_csv(os.getcwd()+'/'+filename)\n",
        "  \n",
        "  df_wheat = df.copy()\n",
        "  df_maize = df.copy()\n",
        "\n",
        "  # to get the columns for wheat\n",
        "  df_wheat = df_wheat.iloc[:,[0,1,3,5,6]]\n",
        "\n",
        "  # to get the years with wheat production\n",
        "  df_wheat = df_wheat.iloc[1::2]\n",
        "\n",
        "  # to get the columns for maize\n",
        "  df_maize = df_maize.iloc[:,[0,2,4,5,6]]\n",
        "\n",
        "  # to get the years with maize production\n",
        "  df_maize = df_maize.iloc[::2]\n",
        "\n",
        "  with pd.ExcelWriter(os.getcwd()+'/'+filename[:-4:]+'.xlsx') as writer:\n",
        "    df_wheat.to_excel(writer, sheet_name='Wheat', index=False)\n",
        "    df_maize.to_excel(writer, sheet_name='Maize', index=False)\n"
      ],
      "metadata": {
        "id": "dJWmCFM9ihhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in filelist:\n",
        "    if item.endswith(\".csv\"):\n",
        "        os.remove(os.path.join(os.getcwd(), item))"
      ],
      "metadata": {
        "id": "8V91uKsZihhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Organic"
      ],
      "metadata": {
        "id": "M2g3-xD8ddUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nitrate"
      ],
      "metadata": {
        "id": "KwOGINPgfvhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_Organic/Nitrate')\n",
        "try:\n",
        "  os.mkdir('newfiles')\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "filelist = sorted(os.listdir())"
      ],
      "metadata": {
        "id": "MxhBnSslJyf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files(filelist[:-1:])"
      ],
      "metadata": {
        "id": "WkM-7J9XJyf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_Organic/Nitrate/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "for filename in filelist:\n",
        "\n",
        "  c = 0\n",
        "\n",
        "  for i in range(3):\n",
        "    if i<2:\n",
        "      replace_line(os.getcwd()+'/'+filename, c, '')\n",
        "    else:\n",
        "      replace_line(os.getcwd()+'/'+filename, c+1, '')\n",
        "\n",
        "  df = pd.read_csv(os.getcwd()+'/'+filename)\n",
        "\n",
        "  del df[df.columns[-1]]\n",
        "\n",
        "  df_new = pd.DataFrame()\n",
        "\n",
        "  for yr in range(1980,2010):\n",
        "    df_new['N'+str(yr)] = pd.Series(list(df[df['year']==yr].iloc[:,2]))\n",
        "\n",
        "  df_new.to_csv(os.getcwd()+'/'+filename,index=False)"
      ],
      "metadata": {
        "id": "sTRvwR16Jyf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yield"
      ],
      "metadata": {
        "id": "YDI7OiMxfwwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_Organic/Yield')\n",
        "try:\n",
        "  os.mkdir('newfiles')\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "filelist = sorted(os.listdir())"
      ],
      "metadata": {
        "id": "0Za8ndIBrBBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new list of files having size > 300 bytes, to then copy into the newfiles directory\n",
        "\n",
        "filelist_copy = []\n",
        "for filename in filelist[:-1:]:\n",
        "  if os.stat(filename).st_size > 300:\n",
        "    filelist_copy.append(filename)\n",
        "\n",
        "filelist = filelist_copy"
      ],
      "metadata": {
        "id": "Nr2YL8lsrBBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_files(filelist[::])"
      ],
      "metadata": {
        "id": "5UuoZdcArBBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_Organic/Yield/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "for filename in filelist:\n",
        "\n",
        "  c = 0\n",
        "\n",
        "  for i in range(3):\n",
        "    if i<2:\n",
        "      replace_line(os.getcwd()+'/'+filename, c, '')\n",
        "    else:\n",
        "      replace_line(os.getcwd()+'/'+filename, c+1, '')\n",
        "\n",
        "  df = pd.read_csv(os.getcwd()+'/'+filename)\n",
        "  \n",
        "  df_wheat = df.copy()\n",
        "  df_maize = df.copy()\n",
        "\n",
        "  # to get the columns for wheat\n",
        "  df_wheat = df_wheat.iloc[:,[0,1,3,5,6]]\n",
        "\n",
        "  # to get the years with wheat production\n",
        "  df_wheat = df_wheat.iloc[1::2]\n",
        "\n",
        "  # to get the columns for maize\n",
        "  df_maize = df_maize.iloc[:,[0,2,4,5,6]]\n",
        "\n",
        "  # to get the years with maize production\n",
        "  df_maize = df_maize.iloc[::2]\n",
        "\n",
        "  with pd.ExcelWriter(os.getcwd()+'/'+filename[:-4:]+'.xlsx') as writer:\n",
        "    df_wheat.to_excel(writer, sheet_name='Wheat', index=False)\n",
        "    df_maize.to_excel(writer, sheet_name='Maize', index=False)\n"
      ],
      "metadata": {
        "id": "wIRqk7k4rBBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in filelist:\n",
        "    if item.endswith(\".csv\"):\n",
        "        os.remove(os.path.join(os.getcwd(), item))"
      ],
      "metadata": {
        "id": "cU0qG7dGrBBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# yield file combining"
      ],
      "metadata": {
        "id": "CQg2xazDaM8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 60%"
      ],
      "metadata": {
        "id": "Ibx-YpZk75XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_wheat = pd.DataFrame({'year':[x for x in range(1981,2010)]})\n",
        "df_maize = df_wheat.copy()"
      ],
      "metadata": {
        "id": "J7VAFnf41fzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_60%/Yield/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "filelist = natsorted(filelist)[-1:] + natsorted(filelist)[:-1]\n",
        "\n",
        "df = [0 for x in range(len(filelist))]\n",
        "df2 = df.copy()\n",
        "\n",
        "count = 0\n",
        "for filename in filelist:\n",
        "  df[count] = pd.read_excel(os.getcwd()+'/'+filename,sheet_name='Wheat')\n",
        "  df_wheat[re.search(r'_(.*?).xlsx', filelist[count]).group(1)] = df[count].iloc[:,2]\n",
        "  df2[count] = pd.read_excel(os.getcwd()+'/'+filename,sheet_name='Maize')\n",
        "  df_maize[re.search(r'_(.*?).xlsx', filelist[count]).group(1)] = df[count].iloc[:,2]\n",
        "  count+=1\n",
        "\n",
        "with pd.ExcelWriter(os.getcwd()+'/'+re.search(r'Copy_M_W_CSV/(.*?)/Yield', os.getcwd()).group(1)+'_combined_yield.xlsx') as writer:\n",
        "    df_wheat.to_excel(writer, sheet_name='Wheat', index=False)\n",
        "    df_maize.to_excel(writer, sheet_name='Maize', index=False)"
      ],
      "metadata": {
        "id": "p2__jOpvdgFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.search(r'Copy_M_W_CSV/(.*?)/Yield', os.getcwd()).group(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wXXkSCbw0jz4",
        "outputId": "5425d70d-ee5a-466b-9a28-2cd43d9bf482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'M_W_60%'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 100%"
      ],
      "metadata": {
        "id": "usEf6nyG78SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_wheat = pd.DataFrame({'year':[x for x in range(1981,2010)]})\n",
        "df_maize = df_wheat.copy()"
      ],
      "metadata": {
        "id": "ZRbgi3vt4GaO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_100%/Yield/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "filelist = natsorted(filelist)[-1:] + natsorted(filelist)[:-1]\n",
        "\n",
        "newfiles = ['Maize Wheat100_N.xlsx'] + ['Maize Wheat100_N'+str(i)+'.xlsx' for i in range(1,100)]"
      ],
      "metadata": {
        "id": "io2VjmlC7_ck"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "\n",
        "for filename in newfiles:\n",
        "  if filename in filelist:\n",
        "    df = pd.read_excel(os.getcwd()+'/'+filename,sheet_name='Wheat')\n",
        "    df2 = pd.read_excel(os.getcwd()+'/'+filename,sheet_name='Maize')\n",
        "    df_wheat[re.search(r'_(.*?).xlsx',filename).group(1)] = df.iloc[:,2]\n",
        "    df_maize[re.search(r'_(.*?).xlsx',filename).group(1)] = df2.iloc[:,2]\n",
        "  else:\n",
        "    df_wheat[re.search(r'_(.*?).xlsx',filename).group(1)] = [np.nan for x in range(1981,2010)]\n",
        "    df_maize[re.search(r'_(.*?).xlsx',filename).group(1)] = [np.nan for x in range(1981,2010)]\n",
        "  count += 1"
      ],
      "metadata": {
        "id": "tdgBA6raM9a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4842792-d574-405a-cb43-adbe1959482a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-9dadd10e047c>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_wheat[re.search(r'_(.*?).xlsx',filename).group(1)] = df.iloc[:,2]\n",
            "<ipython-input-31-9dadd10e047c>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_maize[re.search(r'_(.*?).xlsx',filename).group(1)] = df2.iloc[:,2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.ExcelWriter(os.getcwd()+'/'+re.search(r'Copy_M_W_CSV/(.*?)/Yield', os.getcwd()).group(1)+'_combined_yield.xlsx') as writer:\n",
        "    df_wheat.to_excel(writer, sheet_name='Wheat', index=False)\n",
        "    df_maize.to_excel(writer, sheet_name='Maize', index=False)"
      ],
      "metadata": {
        "id": "X8Fiy15QG85i"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Integrated"
      ],
      "metadata": {
        "id": "CiA6qxTgi2qO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_wheat = pd.DataFrame({'year':[x for x in range(1981,2010)]})\n",
        "df_maize = df_wheat.copy()"
      ],
      "metadata": {
        "id": "Ip0Qedu2i6Mr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_Integrated/Yield/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "filelist = natsorted(filelist)[-1:] + natsorted(filelist)[:-1]\n",
        "\n",
        "newfiles = ['Maize Wheat_INM.xlsx'] + ['Maize Wheat_INM'+str(i)+'.xlsx' for i in range(1,100)]"
      ],
      "metadata": {
        "id": "kVKrhQABi6Mr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "\n",
        "for filename in newfiles:\n",
        "  if filename in filelist:\n",
        "    df = pd.read_excel(os.getcwd()+'/'+filename,sheet_name='Wheat')\n",
        "    df2 = pd.read_excel(os.getcwd()+'/'+filename,sheet_name='Maize')\n",
        "    df_wheat[re.search(r'_(.*?).xlsx',filename).group(1)] = df.iloc[:,2]\n",
        "    df_maize[re.search(r'_(.*?).xlsx',filename).group(1)] = df2.iloc[:,2]\n",
        "  else:\n",
        "    df_wheat[re.search(r'_(.*?).xlsx',filename).group(1)] = [np.nan for x in range(1981,2010)]\n",
        "    df_maize[re.search(r'_(.*?).xlsx',filename).group(1)] = [np.nan for x in range(1981,2010)]\n",
        "  count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720541a7-9dfa-4f64-dc25-28d8318f0c9f",
        "id": "fvPaqqeii6Mr"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-9dadd10e047c>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_wheat[re.search(r'_(.*?).xlsx',filename).group(1)] = df.iloc[:,2]\n",
            "<ipython-input-45-9dadd10e047c>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_maize[re.search(r'_(.*?).xlsx',filename).group(1)] = df2.iloc[:,2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.ExcelWriter(os.getcwd()+'/'+re.search(r'Copy_M_W_CSV/(.*?)/Yield', os.getcwd()).group(1)+'_combined_yield.xlsx') as writer:\n",
        "    df_wheat.to_excel(writer, sheet_name='Wheat', index=False)\n",
        "    df_maize.to_excel(writer, sheet_name='Maize', index=False)"
      ],
      "metadata": {
        "id": "M1E0fnINi6Ms"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organic"
      ],
      "metadata": {
        "id": "flLp2O-OkUoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_wheat = pd.DataFrame({'year':[x for x in range(1981,2010)]})\n",
        "df_maize = df_wheat.copy()"
      ],
      "metadata": {
        "id": "fCqCBd41kW56"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Copy_M_W_CSV/M_W_Organic/Yield/newfiles')\n",
        "filelist = sorted(os.listdir())\n",
        "\n",
        "filelist = natsorted(filelist)[-1:] + natsorted(filelist)[:-1]\n",
        "\n",
        "newfiles = ['Maize Wheat_Org.xlsx'] + ['Maize Wheat_Org'+str(i)+'.xlsx' for i in range(1,100)]"
      ],
      "metadata": {
        "id": "APr9w3PkkW56"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "\n",
        "for filename in newfiles:\n",
        "  if filename in filelist:\n",
        "    df = pd.read_excel(os.getcwd()+'/'+filename,sheet_name='Wheat')\n",
        "    df2 = pd.read_excel(os.getcwd()+'/'+filename,sheet_name='Maize')\n",
        "    df_wheat[re.search(r'_(.*?).xlsx',filename).group(1)] = df.iloc[:,2]\n",
        "    df_maize[re.search(r'_(.*?).xlsx',filename).group(1)] = df2.iloc[:,2]\n",
        "  else:\n",
        "    df_wheat[re.search(r'_(.*?).xlsx',filename).group(1)] = [np.nan for x in range(1981,2010)]\n",
        "    df_maize[re.search(r'_(.*?).xlsx',filename).group(1)] = [np.nan for x in range(1981,2010)]\n",
        "  count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5220d190-eee9-4205-9c32-907417d28a84",
        "id": "wWT3W65HkW56"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-9dadd10e047c>:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_wheat[re.search(r'_(.*?).xlsx',filename).group(1)] = df.iloc[:,2]\n",
            "<ipython-input-54-9dadd10e047c>:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_maize[re.search(r'_(.*?).xlsx',filename).group(1)] = df2.iloc[:,2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.ExcelWriter(os.getcwd()+'/'+re.search(r'Copy_M_W_CSV/(.*?)/Yield', os.getcwd()).group(1)+'_combined_yield.xlsx') as writer:\n",
        "    df_wheat.to_excel(writer, sheet_name='Wheat', index=False)\n",
        "    df_maize.to_excel(writer, sheet_name='Maize', index=False)"
      ],
      "metadata": {
        "id": "9qJ6y9mvkW56"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "irD968jErNBk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}